{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLOXFOT5Q40E"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iiQkM5ZgQ8r2"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6331ZSsQGY3"
      },
      "source": [
        "# MNIST の分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Jcnb8bQQyd"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/quantum/tutorials/mnist\">     <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">     TensorFlow.org で表示</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ja/quantum/tutorials/mnist.ipynb\">     <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">     Google Colab で実行</a>\n",
        "</td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ja/quantum/tutorials/mnist.ipynb\">     <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">     GitHubでソースを表示</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ja/quantum/tutorials/mnist.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">ノートブックをダウンロード</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udLObUVeGfTs"
      },
      "source": [
        "このチュートリアルでは、簡略化された MNIST バージョンを分類する、<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a> で使用されたアプローチに似た量子ニューラルネットワーク（QNN）を構築し、古典的なデータ問題における量子ニューラルネットワークのパフォーマンスを従来のニューラルネットワークと比較します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X35qHdh5Gzqg"
      },
      "source": [
        "## セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TorxE5tnkvb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c295969e-a0af-410e-ab6c-073a51702a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7.0\n",
            "  Downloading https://us-python.pkg.dev/colab-wheels/public/tensorflow/tensorflow-2.7.0%2Bzzzcolab20220506150900-cp37-cp37m-linux_x86_64.whl (665.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 665.5 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.47.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (2.0)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting gast<0.5.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.0) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed gast-0.4.0 keras-2.7.0 tensorflow-2.7.0+zzzcolab20220506150900 tensorflow-estimator-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxkQA6oblNqI"
      },
      "source": [
        "TensorFlow Quantum をインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "saFHsRDpkvkH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ced0a2f-cea4-4cce-ee9d-484c372d7078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-quantum\n",
            "  Downloading tensorflow_quantum-0.7.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos==1.52.0\n",
            "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting cirq-google>=0.13.1\n",
            "  Downloading cirq_google-1.0.0-py3-none-any.whl (576 kB)\n",
            "\u001b[K     |████████████████████████████████| 576 kB 42.7 MB/s \n",
            "\u001b[?25hCollecting cirq-core==0.13.1\n",
            "  Downloading cirq_core-0.13.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.17.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-quantum) (3.17.3)\n",
            "Collecting google-api-core==1.21.0\n",
            "  Downloading google_api_core-1.21.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting sympy==1.8\n",
            "  Downloading sympy-1.8-py3-none-any.whl (6.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.1 MB 35.8 MB/s \n",
            "\u001b[?25hCollecting google-auth==1.18.0\n",
            "  Downloading google_auth-1.18.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (1.3.5)\n",
            "Requirement already satisfied: sortedcontainers~=2.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (2.4.0)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (4.64.0)\n",
            "Collecting duet~=0.2.0\n",
            "  Downloading duet-0.2.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (1.7.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (3.2.2)\n",
            "Requirement already satisfied: networkx~=2.4 in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (2.6.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cirq-core==0.13.1->tensorflow-quantum) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (2022.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.18.0->tensorflow-quantum) (4.2.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy==1.8->tensorflow-quantum) (1.2.1)\n",
            "Collecting proto-plus>=1.20.0\n",
            "  Downloading proto_plus-1.22.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting cirq-google>=0.13.1\n",
            "  Downloading cirq_google-0.15.0-py3-none-any.whl (641 kB)\n",
            "\u001b[K     |████████████████████████████████| 641 kB 53.1 MB/s \n",
            "\u001b[?25h  Downloading cirq_google-0.14.1-py3-none-any.whl (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 38.9 MB/s \n",
            "\u001b[?25h  Downloading cirq_google-0.14.0-py3-none-any.whl (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 53.8 MB/s \n",
            "\u001b[?25h  Downloading cirq_google-0.13.1-py3-none-any.whl (437 kB)\n",
            "\u001b[K     |████████████████████████████████| 437 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from cirq-google>=0.13.1->tensorflow-quantum) (1.31.6)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting google-api-core[grpc]<2.0.0dev,>=1.14.0\n",
            "  Downloading google_api_core-1.32.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.9 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.5-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.8 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.4-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.8 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.9 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.1-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.6 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.6 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.29.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.4 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.28.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.27.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.5 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.2-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.2 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.26.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 1.0 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 291 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.25.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 173 kB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 11.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.24.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 11.1 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 11.5 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.4-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 11.3 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.3-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 10.9 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.2-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.7 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.1-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.8 MB/s \n",
            "\u001b[?25h  Downloading google_api_core-1.22.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core==1.21.0->tensorflow-quantum) (1.47.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->cirq-core==0.13.1->tensorflow-quantum) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tensorflow-quantum) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core==1.21.0->tensorflow-quantum) (3.0.4)\n",
            "Installing collected packages: typing-extensions, googleapis-common-protos, google-auth, sympy, google-api-core, duet, cirq-core, cirq-google, tensorflow-quantum\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.56.4\n",
            "    Uninstalling googleapis-common-protos-1.56.4:\n",
            "      Successfully uninstalled googleapis-common-protos-1.56.4\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 1.35.0\n",
            "    Uninstalling google-auth-1.35.0:\n",
            "      Successfully uninstalled google-auth-1.35.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.7.1\n",
            "    Uninstalling sympy-1.7.1:\n",
            "      Successfully uninstalled sympy-1.7.1\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.31.6\n",
            "    Uninstalling google-api-core-1.31.6:\n",
            "      Successfully uninstalled google-api-core-1.31.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pydata-google-auth 1.4.0 requires google-auth<3.0dev,>=1.25.0; python_version >= \"3.6\", but you have google-auth 1.18.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5, but you have google-api-core 1.21.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cirq-core-0.13.1 cirq-google-0.13.1 duet-0.2.7 google-api-core-1.21.0 google-auth-1.18.0 googleapis-common-protos-1.52.0 sympy-1.8 tensorflow-quantum-0.7.2 typing-extensions-3.10.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow-quantum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Ql5PW-ACO0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd2f46a-d16a-492e-d124-6842e3762701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'pkg_resources' from '/usr/local/lib/python3.7/dist-packages/pkg_resources/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Update package resources to account for version changes.\n",
        "import importlib, pkg_resources\n",
        "importlib.reload(pkg_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdgMMZEBGqyl"
      },
      "source": [
        "次に、TensorFlow とモジュールの依存関係をインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "enZ300Bflq80"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_quantum as tfq\n",
        "\n",
        "import cirq\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from cirq.contrib.svg import SVGCircuit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b08Mmbs8lr81"
      },
      "source": [
        "## 1. データを読み込む\n",
        "\n",
        "このチュートリアルでは、<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> に従って、数字の 3 と 6 を区別する二項分類器を構築します。このセクションでは、次を行うデータ処理を説明します。\n",
        "\n",
        "- Keras から生データを読み込みます。\n",
        "- データセットを 3 と 6 に絞り込みます。\n",
        "- 画像が量子コンピュータに適合するように、画像を縮小します。\n",
        "- 矛盾するサンプルを取り除きます。\n",
        "- バイナリ画像を Cirq 回路に変換します。\n",
        "- Cirq 回路を TensorFlow Quantum 回路に変換します。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDUdGxn-ojgy"
      },
      "source": [
        "### 1.1 生データを読み込む"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZyGXlaKojgz"
      },
      "source": [
        "Keras で配布された MNIST データセットを読み込みます。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d9OSExvCojg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56bfbb2-6987-48ae-a3de-d913e100cfbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 60000\n",
            "Number of original test examples: 10000\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"Number of original training examples:\", len(x_train))\n",
        "print(\"Number of original test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZpbygdGojg3"
      },
      "source": [
        "3 と 6 の数字のみを保持してほかのクラスを取り除くように、データセットを絞り込みます。同時に、`3` を `True`、6 を `False` というように、ラベル `y` をブール型に変換します。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hOw68cCZojg4"
      },
      "outputs": [],
      "source": [
        "def filter_36(x, y):\n",
        "    keep = (y == 3) | (y == 6)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == 3\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p-XEU8egGL6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce1b8de-4359-4a91-977f-6e7c7f729e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of filtered training examples: 12049\n",
            "Number of filtered test examples: 1968\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = filter_36(x_train, y_train)\n",
        "x_test, y_test = filter_36(x_test, y_test)\n",
        "\n",
        "print(\"Number of filtered training examples:\", len(x_train))\n",
        "print(\"Number of filtered test examples:\", len(x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyiaP0Xojg_"
      },
      "source": [
        "最初のサンプルを表示します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j5STP7MbojhA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "4ee13e60-4969-4f00-de28-47b6cf6b3083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f824250f350>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :, 0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNS9sVPQojhC"
      },
      "source": [
        "### 1.2 画像を縮小する"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmmtplIFGL6t"
      },
      "source": [
        "現在の量子コンピュータでは、画像サイズ 28x28 は大きすぎるため、4x4 に縮小します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lbhUdBFWojhE"
      },
      "outputs": [],
      "source": [
        "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOMd7zIjGL6x"
      },
      "source": [
        "サイズ変更を行ったら、もう一度最初のサンプルを表示します。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YIYOtCRIGL6y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "2613d2c4-310d-48ed-8eaa-c31c34e52ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f8241f5a510>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGeF1_qtojhK"
      },
      "source": [
        "### 1.3 矛盾するサンプルを取り除く"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZLkq2yeojhL"
      },
      "source": [
        "<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> の *3.3 Learning to Distinguish Digits* セクションに説明されているように、データセットから両方のクラスに属するラベルが付けられた画像を取り除きます。\n",
        "\n",
        "これは標準的な機械学習の手順ではありませんが、論文の手順に従う目的で追加している手順です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LqOPW0C7ojhL"
      },
      "outputs": [],
      "source": [
        "def remove_contradicting(xs, ys):\n",
        "    mapping = collections.defaultdict(set)\n",
        "    orig_x = {}\n",
        "    # Determine the set of labels for each unique image:\n",
        "    for x,y in zip(xs,ys):\n",
        "       orig_x[tuple(x.flatten())] = x\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "    \n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for flatten_x in mapping:\n",
        "      x = orig_x[flatten_x]\n",
        "      labels = mapping[flatten_x]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(next(iter(labels)))\n",
        "      else:\n",
        "          # Throw out images that match more than one label.\n",
        "          pass\n",
        "    \n",
        "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
        "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
        "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of unique 3s: \", num_uniq_3)\n",
        "    print(\"Number of unique 6s: \", num_uniq_6)\n",
        "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
        "    print()\n",
        "    print(\"Initial number of images: \", len(xs))\n",
        "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
        "    \n",
        "    return np.array(new_x), np.array(new_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMOiJfz_ojhP"
      },
      "source": [
        "取り除いた結果の数量は、レポートされている値に密に一致していませんが、これは正確な手順が指定されていないためです。\n",
        "\n",
        "また、この時点で、矛盾するサンプルをフィルタリングすることで、矛盾するトレーニングサンプルがモデルに絶対に送られないということではありません。次のデータの二項化のステップでは、さらに競合が発生します。 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zpnsAssWojhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ad3563-92c9-48e1-e0c8-4a2e0cf35598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique images: 10387\n",
            "Number of unique 3s:  4912\n",
            "Number of unique 6s:  5426\n",
            "Number of unique contradicting labels (both 3 and 6):  49\n",
            "\n",
            "Initial number of images:  12049\n",
            "Remaining non-contradicting unique images:  10338\n"
          ]
        }
      ],
      "source": [
        "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJ5NVaPojhT"
      },
      "source": [
        "### 1.4 データを量子回路としてエンコードする\n",
        "\n",
        "<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> は、量子コンピュータを使って画像を処理するには、ピクセルの値に応じた状態で、各ピクセルをキュービットで表現するように提案しています。最初のステップでは、バイナリエンコーディングへの変換を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1z8J7OyDojhV"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 0.5\n",
        "\n",
        "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
        "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlJ5NVaPojhU"
      },
      "source": [
        "この時点で矛盾した画像を取り除く場合、193 個しか画像が残らず、これでは有効なトレーニングを行える数量とは言えません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z8J7OyDojhW"
      },
      "outputs": [],
      "source": [
        "_ = remove_contradicting(x_train_bin, y_train_nocon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLyxS9KlojhZ"
      },
      "source": [
        "しきい値を超える値を持つピクセルインデックスのキュービットは、$X$ ゲートを介して循環します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aOu_3-3ZGL61"
      },
      "outputs": [],
      "source": [
        "def convert_to_circuit(image):\n",
        "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
        "    values = np.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit\n",
        "\n",
        "\n",
        "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSCXqzOzojhd"
      },
      "source": [
        "これは最初のサンプルに作成された回路です（回路図には、ゼロゲートのキュービットは表示されていません）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w3POmUEUojhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "711d2239-a0bd-4851-bb29-b739767ed4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f8241ea4050>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "SVGCircuit(x_train_circ[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEQMxCcBojhg"
      },
      "source": [
        "この回路を、画像の値がしきい値を超えるインデックスを比較します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TBIsiXdtojhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3e12ac-39f3-4297-cdf7-c839436a2b98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [3, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "bin_img = x_train_bin[0,:,:,0]\n",
        "indices = np.array(np.where(bin_img)).T\n",
        "indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWZ24w1Oojhk"
      },
      "source": [
        "これらの `Cirq` 回路を `tfq` のテンソルに変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IZStEMk4ojhk"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4USiqeOqGL67"
      },
      "source": [
        "## 2. 量子ニューラルネットワーク\n",
        "\n",
        "画像を分類する量子回路構造に関するガイダンスはほとんどありません。分類は読み出されるキュービットの期待に基づいて行われるため、<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> は、2 つのキュービットゲートを使用して、読み出しキュービットが必ず作用されるようにすることを提案しています。これはある意味、ピクセル全体に小さな<a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">ユニタリ RNN</a>を実行することに似ています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIzawEeojho"
      },
      "source": [
        "### 2.1 モデル回路を構築する\n",
        "\n",
        "次の例では、このレイヤー化アプローチを説明しています。各レイヤーは同一ゲートの *n* 個のインスタンスを使用しており、各データキュービットは読み出しキュービットに影響を与えています。\n",
        "\n",
        "ゲートのレイヤーを回路に追加する簡単なクラスから始めましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-hjxxgU5ojho"
      },
      "outputs": [],
      "source": [
        "class CircuitLayerBuilder():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "    \n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjo5hANFojhr"
      },
      "source": [
        "サンプル回路レイヤーを構築して、どのようになるかを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SzXWOpUGojhs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "f7cda1ea-dd0c-4957-d6fc-a98a853ab239"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7f82400bafd0>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"522.59953125\" height=\"250.0\"><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"492.59953125000004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"129.99353515625\" x2=\"129.99353515625\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"230.73810546875004\" x2=\"230.73810546875004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"331.48267578125007\" x2=\"331.48267578125007\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"432.22724609375007\" x2=\"432.22724609375007\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"55.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-0)</text><rect x=\"89.62125\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"129.99353515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"190.36582031250003\" y=\"105.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-1)</text><rect x=\"190.36582031250003\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"230.73810546875004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"291.11039062500004\" y=\"155.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-2)</text><rect x=\"291.11039062500004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"331.48267578125007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"391.85496093750004\" y=\"205.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^(xx-3)</text><rect x=\"391.85496093750004\" y=\"5.0\" width=\"80.74457031250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"432.22724609375007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
        "                                   readout=cirq.GridQubit(-1,-1))\n",
        "\n",
        "circuit = cirq.Circuit()\n",
        "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
        "SVGCircuit(circuit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-QhPE1pojhu"
      },
      "source": [
        "では、2 レイヤーモデルを構築しましょう。 データ回路サイズに一致するようにし、準備と読み出し演算を含めます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JiALbpwRGL69"
      },
      "outputs": [],
      "source": [
        "def create_quantum_model():\n",
        "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
        "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
        "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
        "    circuit = cirq.Circuit()\n",
        "    \n",
        "    # Prepare the readout qubit.\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "    \n",
        "    builder = CircuitLayerBuilder(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # Then add layers (experiment by adding more).\n",
        "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
        "\n",
        "    # Finally, prepare the readout qubit.\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2QZvVh7vojhx"
      },
      "outputs": [],
      "source": [
        "model_circuit, model_readout = create_quantum_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY7vbY6yfABE"
      },
      "source": [
        "### 2.2 tfq-keras モデルでモデル回路をラップする\n",
        "\n",
        "量子コンポーネントで Keras モデルを構築します。このモデルには、古典的なデータをエンコードする「量子データ」が `x_train_circ` からフィードされます。*パラメータ化された量子回路*レイヤーの `tfq.layers.PQC` を使用して、量子データでモデル回路をトレーニングするモデルです。\n",
        "\n",
        "<a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> は、画像を分類するには、パラメータ化された回路で読み出しキュービットの期待値を使用することを提案しています。期待値は、1 から -1 の値です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZYdf_KOxojh0"
      },
      "outputs": [],
      "source": [
        "# Build the Keras model.\n",
        "model = tf.keras.Sequential([\n",
        "    # The input is the data-circuit, encoded as a tf.string\n",
        "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
        "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "    tfq.layers.PQC(model_circuit, model_readout),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz-FbVc9ojh3"
      },
      "source": [
        "次に、`compile` メソッドを使用して、モデルにトレーニング手順を指定します。\n",
        "\n",
        "期待される読み出しは `[-1,1]` の範囲であるため、ヒンジ損失を最適化すると、ある程度自然な適合となります。\n",
        "\n",
        "注意: もう 1 つの有効なアプローチとして、出力範囲を `[0,1]` にシフトし、モデルがクラス `3` に割りてる確率として扱う方法があります。これは、標準的な`tf.losses.BinaryCrossentropy` 損失で使用することができます。\n",
        "\n",
        "ここでヒンジ損失を使用するには、小さな調整を 2 つ行う必要があります。まず、ラベル `y_train_nocon` をブール型からヒンジ損失が期待する `[-1,1]` に変換することです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CgMNkC1Fojh5"
      },
      "outputs": [],
      "source": [
        "y_train_hinge = 2.0*y_train_nocon-1.0\n",
        "y_test_hinge = 2.0*y_test-1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nwnveDiojh7"
      },
      "source": [
        "次に、`[-1, 1]` を `y_true` ラベル引数として正しく処理するカスタムの `hinge_accuracy` メトリックを使用します。`tf.losses.BinaryAccuracy(threshold=0.0)` は `y_true` がブール型であることを期待するため、ヒンジ損失とは使用できません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3XKtZ_TEojh8"
      },
      "outputs": [],
      "source": [
        "def hinge_accuracy(y_true, y_pred):\n",
        "    y_true = tf.squeeze(y_true) > 0.0\n",
        "    y_pred = tf.squeeze(y_pred) > 0.0\n",
        "    result = tf.cast(y_true == y_pred, tf.float32)\n",
        "\n",
        "    return tf.reduce_mean(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FlpETlLRojiA"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[hinge_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkHq2RstojiC"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsuOzDYblA9s"
      },
      "source": [
        "### 量子モデルをトレーニングする\n",
        "\n",
        "では、モデルをトレーニングしましょう。これには約 45 分かかりますが、その時間を待てない方は、小規模なデータのサブセット（以下の`NUM_EXAMPLES=500` セット）を使用するとよいでしょう。トレーニング時のモデルの進捗にあまり影響はありません（パラメータは 32 しかなく、これらを制約する上であまりデータは必要ありません）。サンプル数を減らすことでトレーニングを早めに（5 分程度）終わらせることができますが、検証ログに進捗状況を示すには十分な長さです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n8vuQpSLlBV2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qJnNG-3JojiI"
      },
      "outputs": [],
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSdgGC1GL7D"
      },
      "source": [
        "このモデルを収束までトレーニングすると、テストセットにおいて 85% を超える精度が達成されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ya9qP3KkojiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7975684-bca8-49ab-fd41-ac22eca095a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "324/324 [==============================] - 716s 2s/step - loss: 0.7327 - hinge_accuracy: 0.7097 - val_loss: 0.3713 - val_hinge_accuracy: 0.8291\n",
            "Epoch 2/3\n",
            "324/324 [==============================] - 717s 2s/step - loss: 0.3657 - hinge_accuracy: 0.8245 - val_loss: 0.3370 - val_hinge_accuracy: 0.8564\n",
            "Epoch 3/3\n",
            "324/324 [==============================] - 715s 2s/step - loss: 0.3467 - hinge_accuracy: 0.8710 - val_loss: 0.3301 - val_hinge_accuracy: 0.9068\n",
            "62/62 [==============================] - 24s 379ms/step - loss: 0.3301 - hinge_accuracy: 0.9068\n"
          ]
        }
      ],
      "source": [
        "qnn_history = model.fit(\n",
        "      x_train_tfcirc_sub, y_train_hinge_sub,\n",
        "      batch_size=32,\n",
        "      epochs=EPOCHS,\n",
        "      verbose=1,\n",
        "      validation_data=(x_test_tfcirc, y_test_hinge))\n",
        "\n",
        "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ER7B7aaojiP"
      },
      "source": [
        "注意: トレーニング精度はエポックの平均値を示します。検証精度はエポックの終了ごとに評価されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8952YvuWGL7J"
      },
      "source": [
        "## 3. 従来のニューラルネットワーク\n",
        "\n",
        "量子ニューラルネットワークは、この単純化された MNIST 問題で機能するものの、このタスクでは、従来のニューラルネットワークの性能が QNN をはるかに上回ります。1 つのエポックが終了した時点で、従来のニューラルネットワークは縮小したセットで 98% を超える精度を達成することができます。\n",
        "\n",
        "次の例では、画像をサブサンプリングする代わりに 28x28 の画像を使用した 3 と 6 の分類問題に従来のニューラルネットワークを使用しています。これはほぼ 100% 精度のテストセットに難なく収束します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZofEHhLGL7L"
      },
      "outputs": [],
      "source": [
        "def create_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(0.25))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiAJl7sZojiU"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "cnn_results = model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5-5BVJaojiZ"
      },
      "source": [
        "上記のモデルには約 120 万個のパラメータがあります。より公正な比較を行うために、サブサンプリングした画像で 37 個のパラメータモデルを使用してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70TOM6r-ojiZ"
      },
      "outputs": [],
      "source": [
        "def create_fair_classical_model():\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
        "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_fair_classical_model()\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA_Fx-8gojid"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_bin,\n",
        "          y_train_nocon,\n",
        "          batch_size=128,\n",
        "          epochs=20,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test_bin, y_test))\n",
        "\n",
        "fair_nn_results = model.evaluate(x_test_bin, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH3mam7EGL7N"
      },
      "source": [
        "## 4. 比較\n",
        "\n",
        "解像度の高い入力とより強力なモデルの場合、CNN はこの問題を簡単に解決できますが、似たようなパワー（最大 32 個のパラメータ）を持つ古典的モデルはわずかな時間で似たような精度までトレーニングすることができます。いずれにせよ、従来のニューラルネットワークは量子ニューラルネットワークの性能を簡単に上回ります。古典的なデータでは、従来のニューラルネットワークを上回るのは困難といえます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOMeN7pMGL7P"
      },
      "outputs": [],
      "source": [
        "qnn_accuracy = qnn_results[1]\n",
        "cnn_accuracy = cnn_results[1]\n",
        "fair_nn_accuracy = fair_nn_results[1]\n",
        "\n",
        "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
        "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mnist.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}